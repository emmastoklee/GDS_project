{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is retrieved from Michel's notebook\n",
    "# READ: https://hatchjs.com/graph-from-place-osmnx/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd # for geospatial data handling\n",
    "import pandas as pd\n",
    "import osmnx as ox # for handling data from OpenStreetMap (osm) with the help of networkX (nx)\n",
    "import contextily as cx # for plotting\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "from pyproj import CRS # for more advanced CRS modifications and transformations\n",
    "from shapely.geometry import Polygon\n",
    "import numpy as np\n",
    "import pandana as pdna\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ONLY ONCE TO SAVE THE GRAPHS - ALREADY DONE\n",
    "\n",
    "# walking_graphs = {}\n",
    "\n",
    "# # specify parameters for the analysis\n",
    "# walk_time = 15  # max walking horizon in minutes\n",
    "# walk_speed = 5  # km per hour\n",
    "# walk_time_sec = walk_time * 60 # We need the time in seconds to match how travel time is calculated in OSMnx\n",
    "\n",
    "# # Loop through the neighborhoods\n",
    "# for neighborhood in tqdm(neighbourhoods):\n",
    "#     # Create a graph for the current neighborhood\n",
    "#     G_walk_neighborhood = ox.graph_from_place(neighborhood, network_type='walk') # type of transportation is set here\n",
    "\n",
    "#     for u, v, data in G_walk_neighborhood.edges(data=True):\n",
    "#         data['speed_kph'] = walk_speed\n",
    "#     G_walk_neighborhood = ox.add_edge_travel_times(G_walk_neighborhood) # this computes the travel time in seconds based on the 'speed_kph' column\n",
    "\n",
    "# # caro path\n",
    "#     # ox.save_graphml(G_walk_neighborhood, f\"/Users/caro/Desktop/SPRING24/GDS/PROJECT/graphs/G_walk_{neighborhood}.graphml\") # save graph per neighbourhood\n",
    "# # michel path\n",
    "#     ox.save_graphml(G_walk_neighborhood, f\"../graphs/G_walk_{neighborhood}.graphml\") # save graph per neighbourhood\n",
    "#     # Store the graph in the dictionary using the neighborhood name as the key\n",
    "#     walking_graphs[neighborhood] = G_walk_neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "place = 'Montreal, Canada'\n",
    "# list_of_amenities = ['restaurant', 'cafe', 'pharmacy', 'hospital', 'parking']\n",
    "list_of_amenities = [\n",
    "    \"restaurant\",\n",
    "    \"post_box\",\n",
    "    \"pub\",\n",
    "    \"atm\",\n",
    "    \"townhall\",\n",
    "    \"post_office\",\n",
    "    \"kindergarten\",\n",
    "    \"cinema\",\n",
    "    \"cafe\",\n",
    "    \"fire_station\",\n",
    "    \"bank\",\n",
    "    \"school\",\n",
    "    \"place_of_worship\",\n",
    "    \"childcare\",\n",
    "    \"police\",\n",
    "    \"pharmacy\",\n",
    "    \"fast_food\",\n",
    "    \"library\",\n",
    "    \"clinic\",\n",
    "    \"bar\",\n",
    "    \"dentist\",\n",
    "    \"theatre\",\n",
    "    \"ice_cream\",\n",
    "    \"doctors\",\n",
    "    \"community_centre\",\n",
    "    \"bureau_de_change\",\n",
    "    \"veterinary\",\n",
    "    \"arts_centre\",\n",
    "    \"studio\",\n",
    "    \"nightclub\",\n",
    "    \"recycling\",\n",
    "    \"marketplace\",\n",
    "    \"college\",\n",
    "    \"social_facility\",\n",
    "    \"hospital\",\n",
    "    \"social_centre\",\n",
    "    \"university\",\n",
    "    \"events_venue\",\n",
    "    \"public_building\"\n",
    "]\n",
    "tags = {'amenity': list_of_amenities}\n",
    "\n",
    "walk_time = 15  # max walking horizon in minutes\n",
    "walk_speed = 5  # km per hour\n",
    "walk_time_sec = walk_time * 60 # We need the time in seconds to match how travel time is calculated in OSMnx\n",
    "\n",
    "bike_time = 15  # max walking horizon in minutes\n",
    "bike_speed = 15  # km per hour\n",
    "bike_time_sec = bike_time * 60 # We need the time in seconds to match how travel time is calculated in OSMnx\n",
    "\n",
    "drive_time = 15\n",
    "drive_speed = 50\n",
    "drive_time_sec = drive_time * 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:02<00:00,  6.30it/s]\n",
      " 11%|█         | 2/18 [00:00<00:03,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 1589\n",
      "Setting CH edge vector of size 3865\n",
      "Range graph removed 2722 edges of 7730\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 946\n",
      "Setting CH edge vector of size 2338\n",
      "Range graph removed 1526 edges of 4676\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 663\n",
      "Setting CH edge vector of size 1496\n",
      "Range graph removed 762 edges of 2992\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4/18 [00:02<00:08,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 1938\n",
      "Setting CH edge vector of size 5262\n",
      "Range graph removed 4600 edges of 10524\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 297\n",
      "Setting CH edge vector of size 767\n",
      "Range graph removed 554 edges of 1534\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 6/18 [00:02<00:06,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 890\n",
      "Setting CH edge vector of size 2182\n",
      "Range graph removed 1386 edges of 4364\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 910\n",
      "Setting CH edge vector of size 2487\n",
      "Range graph removed 2210 edges of 4974\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 9/18 [00:05<00:05,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 742\n",
      "Setting CH edge vector of size 1748\n",
      "Range graph removed 1286 edges of 3496\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 908\n",
      "Setting CH edge vector of size 2466\n",
      "Range graph removed 2164 edges of 4932\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 10/18 [00:06<00:07,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 949\n",
      "Setting CH edge vector of size 2170\n",
      "Range graph removed 1338 edges of 4340\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 11/18 [00:07<00:06,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 1102\n",
      "Setting CH edge vector of size 2547\n",
      "Range graph removed 1494 edges of 5094\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 1483\n",
      "Setting CH edge vector of size 3641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 13/18 [00:08<00:02,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range graph removed 2420 edges of 7282\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 568\n",
      "Setting CH edge vector of size 1547\n",
      "Range graph removed 1716 edges of 3094\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 14/18 [00:08<00:01,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 1174\n",
      "Setting CH edge vector of size 2438\n",
      "Range graph removed 1158 edges of 4876\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% Generating contraction hierarchies with 16 threads.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 16/18 [00:08<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CH node vector of size 1744\n",
      "Setting CH edge vector of size 4113\n",
      "Range graph removed 2838 edges of 8226\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 1181\n",
      "Setting CH edge vector of size 2743\n",
      "Range graph removed 1722 edges of 5486\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:09<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 242\n",
      "Setting CH edge vector of size 620\n",
      "Range graph removed 502 edges of 1240\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 713\n",
      "Setting CH edge vector of size 1793\n",
      "Range graph removed 1478 edges of 3586\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 50.66it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 71.01it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 91.39it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 107.21it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 64.02it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 116.50it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 109.51it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 93.54it/s] \n",
      "100%|██████████| 18/18 [00:00<00:00, 41.66it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 47.61it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 40.60it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 45.64it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 36.76it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 50.12it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 40.38it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 47.12it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 51.82it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 75.02it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 52.26it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 51.02it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 46.50it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 60.58it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 105.16it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 109.23it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 94.85it/s] \n",
      "100%|██████████| 18/18 [00:00<00:00, 64.39it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 106.39it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 98.87it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 102.00it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.07it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 79.10it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 100.15it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 94.50it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 72.35it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 46.93it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 86.83it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 90.23it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 108.87it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 106.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# DRIVING\n",
    "\n",
    "amenities = ox.features_from_place(place, tags=tags)\n",
    "amenities = amenities.to_crs('EPSG:25832')\n",
    "\n",
    "# Dictionary to store centroids for each amenity\n",
    "centroids_per_amenity = {}\n",
    "\n",
    "# Loop through each amenity category\n",
    "for amenity in list_of_amenities:\n",
    "    # Filter amenities for the current category\n",
    "    amenities_category = amenities[amenities['amenity'] == amenity]\n",
    "    # Calculate centroids for the current category\n",
    "    centroids_category = amenities_category.centroid\n",
    "    # Store centroids for the current category in the dictionary\n",
    "    centroids_per_amenity[amenity] = centroids_category\n",
    "\n",
    "# graphs_dir = '/Users/caro/Desktop/SPRING24/GDS/PROJECT/GDS_project/graphs/drive'\n",
    "graphs_dir = '../graphs/drive'\n",
    "\n",
    "driving_graphs = {}\n",
    "for file_name in tqdm(os.listdir(graphs_dir)):\n",
    "    if file_name.endswith(\".graphml\"):\n",
    "        neighborhood = file_name.replace(\"G_drive_\", \"\").replace(\".graphml\", \"\")\n",
    "        file_path = os.path.join(graphs_dir, file_name)\n",
    "        G_drive_neighborhood = ox.load_graphml(file_path)\n",
    "        driving_graphs[neighborhood] = G_drive_neighborhood\n",
    "            \n",
    "\n",
    "drive_pandanas = {}\n",
    "# Build Pandana network for each neighborhood\n",
    "for neighborhood, graph in tqdm(driving_graphs.items()):\n",
    "    graph = ox.project_graph(graph, to_crs='EPSG:25832')\n",
    "    nodes = ox.graph_to_gdfs(graph, edges=False)[['x', 'y']]\n",
    "    edges = ox.graph_to_gdfs(graph, nodes=False).reset_index()[['u', 'v', 'travel_time']]\n",
    "    \n",
    "    network = pdna.Network(node_x=nodes['x'],\n",
    "                            node_y=nodes['y'], \n",
    "                            edge_from=edges['u'],\n",
    "                            edge_to=edges['v'],\n",
    "                            edge_weights=edges[['travel_time']])\n",
    "    \n",
    "    drive_pandanas[neighborhood] = network\n",
    "\n",
    "\n",
    "driving_distances = {}  # Initialize an empty dictionary to store distances for each amenity\n",
    "\n",
    "for amenity in list_of_amenities:\n",
    "    driving_distances[amenity] = {}\n",
    "\n",
    "    for neighborhood, pandana in tqdm(drive_pandanas.items()):\n",
    "        # Set points of interest (POIs) for the current amenity in the current neighborhood\n",
    "        pandana.set_pois(category=amenity,  # Set the current amenity category dynamically\n",
    "                        maxdist=drive_time_sec,\n",
    "                        maxitems=3,\n",
    "                        x_col=centroids_per_amenity[amenity].x,  # Use the centroid of the current amenity\n",
    "                        y_col=centroids_per_amenity[amenity].y)\n",
    "        \n",
    "        # Find the nearest POIs for the current amenity in the current neighborhood\n",
    "        distances = pandana.nearest_pois(distance=drive_time_sec,\n",
    "                                        category=amenity,  # Set the current amenity category dynamically\n",
    "                                        num_pois=3)\n",
    "        \n",
    "        # Convert travel time from seconds to minutes\n",
    "        distances['travel_time'] = distances[1] / 60\n",
    "        \n",
    "        # Store the distances for the current amenity in the current neighborhood\n",
    "        driving_distances[amenity][neighborhood] = distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/micp/.local/lib/python3.10/site-packages/pyarrow/pandas_compat.py:373: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "# Iterate through each amenity and its corresponding DataFrame\n",
    "for amenity, neighborhood_df_dict in driving_distances.items(): # CHANGE HERE\n",
    "    # Iterate through each neighborhood DataFrame\n",
    "    for neighborhood, df in neighborhood_df_dict.items():\n",
    "        # Add a column for 'amenity' and 'neighborhood' to the DataFrame\n",
    "        df['amenity'] = amenity\n",
    "        df['neighborhood'] = neighborhood\n",
    "        \n",
    "        # Append the modified DataFrame to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list along the rows axis\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Assuming your DataFrame is named combined_df\n",
    "combined_df.to_parquet('../distances/driving_distances.parquet', index=False)  # Set index=False if you don't want to save the index. CHANGE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:26<00:00,  1.47s/it]\n",
      "  6%|▌         | 1/18 [00:04<01:09,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 3382\n",
      "Setting CH edge vector of size 10774\n",
      "Range graph removed 10912 edges of 21548\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 2/18 [00:14<02:02,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 8890\n",
      "Setting CH edge vector of size 29956\n",
      "Range graph removed 30224 edges of 59912\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3/18 [00:27<02:29,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 14970\n",
      "Setting CH edge vector of size 48624\n",
      "Range graph removed 48876 edges of 97248\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4/18 [00:28<01:31,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 3603\n",
      "Setting CH edge vector of size 11218\n",
      "Range graph removed 11360 edges of 22436\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 5/18 [00:31<01:10,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 12319\n",
      "Setting CH edge vector of size 38440\n",
      "Range graph removed 38976 edges of 76880\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 6/18 [00:32<00:46,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 1552\n",
      "Setting CH edge vector of size 4430\n",
      "Range graph removed 4700 edges of 8860\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 7/18 [00:36<00:41,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 9720\n",
      "Setting CH edge vector of size 31244\n",
      "Range graph removed 31622 edges of 62488\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 8/18 [00:40<00:40,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 13822\n",
      "Setting CH edge vector of size 43760\n",
      "Range graph removed 44322 edges of 87520\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 9/18 [00:43<00:33,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 6417\n",
      "Setting CH edge vector of size 20386\n",
      "Range graph removed 20608 edges of 40772\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 10/18 [00:44<00:22,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 3200\n",
      "Setting CH edge vector of size 9782\n",
      "Range graph removed 9918 edges of 19564\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 11/18 [00:44<00:14,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 1441\n",
      "Setting CH edge vector of size 4694\n",
      "Range graph removed 4774 edges of 9388\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 12/18 [00:45<00:10,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 3795\n",
      "Setting CH edge vector of size 11622\n",
      "Range graph removed 11734 edges of 23244\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 13/18 [00:49<00:11,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 9639\n",
      "Setting CH edge vector of size 30838\n",
      "Range graph removed 31100 edges of 61676\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 14/18 [00:54<00:12,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 14281\n",
      "Setting CH edge vector of size 46136\n",
      "Range graph removed 46506 edges of 92272\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 15/18 [00:57<00:09,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 10411\n",
      "Setting CH edge vector of size 33610\n",
      "Range graph removed 33746 edges of 67220\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 16/18 [00:58<00:04,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 2588\n",
      "Setting CH edge vector of size 8290\n",
      "Range graph removed 8386 edges of 16580\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 17/18 [00:59<00:01,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 3761\n",
      "Setting CH edge vector of size 11500\n",
      "Range graph removed 11874 edges of 23000\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [01:05<00:00,  3.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 16731\n",
      "Setting CH edge vector of size 55202\n",
      "Range graph removed 55584 edges of 110404\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:01<00:00, 14.83it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 13.07it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 20.06it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 19.42it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 14.11it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 16.09it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 12.89it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 20.74it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 15.79it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 13.11it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 19.15it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 13.33it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 19.31it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 18.50it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 13.03it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 17.40it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 14.73it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 12.02it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 17.19it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 10.96it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 19.75it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 21.84it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 15.03it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 21.15it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 12.23it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 20.70it/s]\n",
      "100%|██████████| 18/18 [00:02<00:00,  8.73it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00,  9.22it/s]\n",
      "100%|██████████| 18/18 [00:02<00:00,  6.81it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 11.85it/s]\n",
      "100%|██████████| 18/18 [00:02<00:00,  6.69it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 20.77it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 13.88it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 16.36it/s]\n",
      "100%|██████████| 18/18 [00:16<00:00,  1.12it/s]\n",
      "100%|██████████| 18/18 [00:02<00:00,  6.13it/s]\n",
      "100%|██████████| 18/18 [00:02<00:00,  6.25it/s]\n",
      "100%|██████████| 18/18 [00:20<00:00,  1.14s/it]\n",
      "100%|██████████| 18/18 [00:01<00:00, 12.28it/s]\n",
      "/home/micp/.local/lib/python3.10/site-packages/pyarrow/pandas_compat.py:373: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# WALKING\n",
    "\n",
    "amenities = ox.features_from_place(place, tags=tags)\n",
    "amenities = amenities.to_crs('EPSG:25832')\n",
    "\n",
    "# Dictionary to store centroids for each amenity\n",
    "centroids_per_amenity = {}\n",
    "\n",
    "# Loop through each amenity category\n",
    "for amenity in list_of_amenities:\n",
    "    # Filter amenities for the current category\n",
    "    amenities_category = amenities[amenities['amenity'] == amenity]\n",
    "    # Calculate centroids for the current category\n",
    "    centroids_category = amenities_category.centroid\n",
    "    # Store centroids for the current category in the dictionary\n",
    "    centroids_per_amenity[amenity] = centroids_category\n",
    "\n",
    "# graphs_dir = '/Users/caro/Desktop/SPRING24/GDS/PROJECT/GDS_project/graphs/walk'\n",
    "graphs_dir = '../graphs/walk'\n",
    "\n",
    "walking_graphs = {}\n",
    "for file_name in tqdm(os.listdir(graphs_dir)):\n",
    "    if file_name.endswith(\".graphml\"):\n",
    "        neighborhood = file_name.replace(\"G_walk_\", \"\").replace(\".graphml\", \"\")\n",
    "        file_path = os.path.join(graphs_dir, file_name)\n",
    "        G_walk_neighborhood = ox.load_graphml(file_path)\n",
    "        walking_graphs[neighborhood] = G_walk_neighborhood\n",
    "            \n",
    "\n",
    "walk_pandanas = {}\n",
    "# Build Pandana network for each neighborhood\n",
    "for neighborhood, graph in tqdm(walking_graphs.items()):\n",
    "    graph = ox.project_graph(graph, to_crs='EPSG:25832')\n",
    "    nodes = ox.graph_to_gdfs(graph, edges=False)[['x', 'y']]\n",
    "    edges = ox.graph_to_gdfs(graph, nodes=False).reset_index()[['u', 'v', 'travel_time']]\n",
    "    \n",
    "    network = pdna.Network(node_x=nodes['x'],\n",
    "                            node_y=nodes['y'], \n",
    "                            edge_from=edges['u'],\n",
    "                            edge_to=edges['v'],\n",
    "                            edge_weights=edges[['travel_time']])\n",
    "    \n",
    "    walk_pandanas[neighborhood] = network\n",
    "\n",
    "\n",
    "walking_distances = {}  # Initialize an empty dictionary to store distances for each amenity\n",
    "\n",
    "for amenity in list_of_amenities:\n",
    "    walking_distances[amenity] = {}\n",
    "\n",
    "    for neighborhood, pandana in tqdm(walk_pandanas.items()):\n",
    "        # Set points of interest (POIs) for the current amenity in the current neighborhood\n",
    "        pandana.set_pois(category=amenity,  # Set the current amenity category dynamically\n",
    "                        maxdist=walk_time_sec,\n",
    "                        maxitems=3,\n",
    "                        x_col=centroids_per_amenity[amenity].x,  # Use the centroid of the current amenity\n",
    "                        y_col=centroids_per_amenity[amenity].y)\n",
    "        \n",
    "        # Find the nearest POIs for the current amenity in the current neighborhood\n",
    "        distances = pandana.nearest_pois(distance=walk_time_sec,\n",
    "                                        category=amenity,  # Set the current amenity category dynamically\n",
    "                                        num_pois=3)\n",
    "        \n",
    "        # Convert travel time from seconds to minutes\n",
    "        distances['travel_time'] = distances[1] / 60\n",
    "        \n",
    "        # Store the distances for the current amenity in the current neighborhood\n",
    "        walking_distances[amenity][neighborhood] = distances\n",
    "        \n",
    "dfs = []\n",
    "\n",
    "# Iterate through each amenity and its corresponding DataFrame\n",
    "for amenity, neighborhood_df_dict in walking_distances.items(): # CHANGE HERE\n",
    "    # Iterate through each neighborhood DataFrame\n",
    "    for neighborhood, df in neighborhood_df_dict.items():\n",
    "        # Add a column for 'amenity' and 'neighborhood' to the DataFrame\n",
    "        df['amenity'] = amenity\n",
    "        df['neighborhood'] = neighborhood\n",
    "        \n",
    "        # Append the modified DataFrame to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list along the rows axis\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Assuming your DataFrame is named combined_df\n",
    "combined_df.to_parquet('../distances/walking_distances.parquet', index=False)  # Set index=False if you don't want to save the index. CHANGE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "# Iterate through each amenity and its corresponding DataFrame\n",
    "for amenity, neighborhood_df_dict in walking_distances.items(): # CHANGE HERE\n",
    "    # Iterate through each neighborhood DataFrame\n",
    "    for neighborhood, df in neighborhood_df_dict.items():\n",
    "        # Add a column for 'amenity' and 'neighborhood' to the DataFrame\n",
    "        df['amenity'] = amenity\n",
    "        df['neighborhood'] = neighborhood\n",
    "        \n",
    "        # Append the modified DataFrame to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list along the rows axis\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Assuming your DataFrame is named combined_df\n",
    "combined_df.to_parquet('../distances/walking_distances.parquet', index=False)  # Set index=False if you don't want to save the index. CHANGE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:08<00:00,  2.10it/s]\n",
      "  6%|▌         | 1/18 [00:00<00:16,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 3035\n",
      "Setting CH edge vector of size 8320\n",
      "Range graph removed 7628 edges of 16640\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 2/18 [00:01<00:10,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 2740\n",
      "Setting CH edge vector of size 7361\n",
      "Range graph removed 6826 edges of 14722\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3/18 [00:01<00:07,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 2141\n",
      "Setting CH edge vector of size 5841\n",
      "Range graph removed 5418 edges of 11682\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4/18 [00:02<00:10,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 6082\n",
      "Setting CH edge vector of size 15235\n",
      "Range graph removed 13594 edges of 30470\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 5/18 [00:03<00:08,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 4071\n",
      "Setting CH edge vector of size 10468\n",
      "Range graph removed 8574 edges of 20936\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 6/18 [00:04<00:08,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 4751\n",
      "Setting CH edge vector of size 11331\n",
      "Range graph removed 9514 edges of 22662\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 7/18 [00:04<00:07,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 3803\n",
      "Setting CH edge vector of size 9427\n",
      "Range graph removed 7296 edges of 18854\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 9/18 [00:05<00:03,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 2086\n",
      "Setting CH edge vector of size 5221\n",
      "Range graph removed 4562 edges of 10442\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 1147\n",
      "Setting CH edge vector of size 3094\n",
      "Range graph removed 3326 edges of 6188\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 10/18 [00:06<00:06,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 3020\n",
      "Setting CH edge vector of size 7292\n",
      "Range graph removed 5542 edges of 14584\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 11/18 [00:08<00:07,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 3218\n",
      "Setting CH edge vector of size 7695\n",
      "Range graph removed 6318 edges of 15390\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 1301\n",
      "Setting CH edge vector of size 3302\n",
      "Range graph removed 3070 edges of 6604\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 13/18 [00:09<00:04,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 4189\n",
      "Setting CH edge vector of size 10148\n",
      "Range graph removed 8728 edges of 20296\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 14/18 [00:10<00:03,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 2232\n",
      "Setting CH edge vector of size 5441\n",
      "Range graph removed 3868 edges of 10882\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 1318\n",
      "Setting CH edge vector of size 3276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 15/18 [00:10<00:02,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range graph removed 2738 edges of 6552\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 600\n",
      "Setting CH edge vector of size 1539\n",
      "Range graph removed 1318 edges of 3078\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 17/18 [00:11<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 1256\n",
      "Setting CH edge vector of size 3212\n",
      "Range graph removed 2388 edges of 6424\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n",
      " 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:12<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 16 threads.\n",
      "Setting CH node vector of size 3848\n",
      "Setting CH edge vector of size 8718\n",
      "Range graph removed 6660 edges of 17436\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 36.93it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 44.40it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 50.68it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 48.07it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 53.38it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 50.70it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 30.02it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 49.79it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 43.90it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 52.30it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 47.37it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 36.41it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 44.99it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 52.69it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 51.55it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 41.41it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 42.04it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 23.38it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 40.87it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 39.09it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 46.72it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 45.15it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 41.86it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 40.57it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 37.74it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 31.90it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 39.32it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 21.90it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 32.70it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 41.87it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 41.79it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 49.89it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 47.54it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 44.42it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 34.53it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 24.40it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 23.74it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 21.76it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 19.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# BIKING\n",
    "\n",
    "amenities = ox.features_from_place(place, tags=tags)\n",
    "amenities = amenities.to_crs('EPSG:25832')\n",
    "\n",
    "# Dictionary to store centroids for each amenity\n",
    "centroids_per_amenity = {}\n",
    "\n",
    "# Loop through each amenity category\n",
    "for amenity in list_of_amenities:\n",
    "    # Filter amenities for the current category\n",
    "    amenities_category = amenities[amenities['amenity'] == amenity]\n",
    "    # Calculate centroids for the current category\n",
    "    centroids_category = amenities_category.centroid\n",
    "    # Store centroids for the current category in the dictionary\n",
    "    centroids_per_amenity[amenity] = centroids_category\n",
    "\n",
    "biking_graphs = {}\n",
    "# graphs_dir = '/Users/caro/Desktop/SPRING24/GDS/PROJECT/GDS_project/graphs/bike'\n",
    "graphs_dir = '../graphs/bike'\n",
    "\n",
    "if biking_graphs == {}:\n",
    "    for file_name in tqdm(os.listdir(graphs_dir)):\n",
    "        if file_name.endswith(\".graphml\"):\n",
    "            neighborhood = file_name.replace(\"G_bike_\", \"\").replace(\".graphml\", \"\")\n",
    "            file_path = os.path.join(graphs_dir, file_name)\n",
    "            G_bike_neighborhood = ox.load_graphml(file_path)\n",
    "            biking_graphs[neighborhood] = G_bike_neighborhood\n",
    "            \n",
    "\n",
    "bike_pandanas = {}\n",
    "# Build Pandana network for each neighborhood\n",
    "for neighborhood, graph in tqdm(biking_graphs.items()):\n",
    "    graph = ox.project_graph(graph, to_crs='EPSG:25832')\n",
    "    nodes = ox.graph_to_gdfs(graph, edges=False)[['x', 'y']]\n",
    "    edges = ox.graph_to_gdfs(graph, nodes=False).reset_index()[['u', 'v', 'travel_time']]\n",
    "    \n",
    "    network = pdna.Network(node_x=nodes['x'],\n",
    "                            node_y=nodes['y'], \n",
    "                            edge_from=edges['u'],\n",
    "                            edge_to=edges['v'],\n",
    "                            edge_weights=edges[['travel_time']])\n",
    "    \n",
    "    bike_pandanas[neighborhood] = network\n",
    "\n",
    "\n",
    "biking_distances = {}  # Initialize an empty dictionary to store distances for each amenity\n",
    "\n",
    "for amenity in list_of_amenities:\n",
    "    biking_distances[amenity] = {}\n",
    "\n",
    "    for neighborhood, pandana in tqdm(bike_pandanas.items()):\n",
    "        # Set points of interest (POIs) for the current amenity in the current neighborhood\n",
    "        pandana.set_pois(category=amenity,  # Set the current amenity category dynamically\n",
    "                        maxdist=bike_time_sec,\n",
    "                        maxitems=3,\n",
    "                        x_col=centroids_per_amenity[amenity].x,  # Use the centroid of the current amenity\n",
    "                        y_col=centroids_per_amenity[amenity].y)\n",
    "        \n",
    "        # Find the nearest POIs for the current amenity in the current neighborhood\n",
    "        distances = pandana.nearest_pois(distance=bike_time_sec,\n",
    "                                        category=amenity,  # Set the current amenity category dynamically\n",
    "                                        num_pois=3)\n",
    "        \n",
    "        # Convert travel time from seconds to minutes\n",
    "        distances['travel_time'] = distances[1] / 60\n",
    "        \n",
    "        # Store the distances for the current amenity in the current neighborhood\n",
    "        biking_distances[amenity][neighborhood] = distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/micp/.local/lib/python3.10/site-packages/pyarrow/pandas_compat.py:373: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "# Iterate through each amenity and its corresponding DataFrame\n",
    "for amenity, neighborhood_df_dict in biking_distances.items(): # CHANGE HERE\n",
    "    # Iterate through each neighborhood DataFrame\n",
    "    for neighborhood, df in neighborhood_df_dict.items():\n",
    "        # Add a column for 'amenity' and 'neighborhood' to the DataFrame\n",
    "        df['amenity'] = amenity\n",
    "        df['neighborhood'] = neighborhood\n",
    "        \n",
    "        # Append the modified DataFrame to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list along the rows axis\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Assuming your DataFrame is named combined_df\n",
    "combined_df.to_parquet('../distances/biking_distances.parquet', index=False)  # Set index=False if you don't want to save the index. CHANGE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcombined_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneighborhood\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_df' is not defined"
     ]
    }
   ],
   "source": [
    "combined_df['neighborhood'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting\n",
    "def plot_neighborhood_graph(transportation_type, neighbourhood, distances_by_transportation, amenity):\n",
    "    \n",
    "    # Load the appropriate graph based on the transportation type\n",
    "    if transportation_type == \"walking\":\n",
    "        G = walking_graphs[f\"{neighbourhood}, Montreal, Canada\"]\n",
    "    elif transportation_type == \"driving\":\n",
    "        G = driving_graphs[f\"{neighbourhood}, Montreal, Canada\"]\n",
    "    elif transportation_type == \"biking\":\n",
    "        G = biking_graphs[f\"{neighbourhood}, Montreal, Canada\"]\n",
    "    # CRS\n",
    "    G_proj = ox.project_graph(G)\n",
    "    \n",
    "    distances = distances_by_transportation[amenity][f\"{neighbourhood}, Montreal, Canada\"]\n",
    "    \n",
    "    # Plot the graph with a light background\n",
    "    fig, ax = ox.plot_graph(G_proj, figsize=(10, 8), bgcolor='white', edge_color='#CCCCCC', edge_linewidth=0.5, node_size=0, show=False, close=False)\n",
    "    \n",
    "    # Assuming 'nodes_anjou' is a DataFrame containing node positions and 'distances_anjou' contains the data to plot\n",
    "    nodes_proj = ox.graph_to_gdfs(G_proj, edges=False)\n",
    "    \n",
    "    # Scatter plot on the same Axes instance\n",
    "    sc = ax.scatter(x=nodes_proj[\"x\"], y=nodes_proj[\"y\"], c=distances['travel_time'], s=30, cmap='inferno_r', alpha=0.8)\n",
    "    \n",
    "    # Add colorbar\n",
    "    plt.colorbar(sc, ax=ax, shrink=0.7)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example usage\n",
    "plot_neighborhood_graph(transportation_type='biking',\n",
    "                        neighbourhood='Saint-Laurent',\n",
    "                        distances_by_transportation=biking_distances,\n",
    "                        amenity='pharmacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_neighborhood_graph(transportation_type='biking',\n",
    "                        neighbourhood='Saint-Laurent', \n",
    "                        distances_by_transportation=biking_distances, \n",
    "                        amenity='hospital')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_neighborhood_graph(transportation_type='walking',\n",
    "                        neighbourhood='Saint-Laurent', \n",
    "                        distances_by_transportation=walking_distances, \n",
    "                        amenity='hospital')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_neighborhood_graph(transportation_type='driving',\n",
    "                        neighbourhood='Côte-des-Neiges–Notre-Dame-de-Grâce', \n",
    "                        distances_by_transportation=driving_distances, \n",
    "                        amenity='restaurant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_neighborhood_graph(transportation_type='driving',\n",
    "                        neighbourhood='Saint-Laurent', \n",
    "                        distances_by_transportation=driving_distances, \n",
    "                        amenity='restaurant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_neighborhood_graph(transportation_type='walking',\n",
    "                        neighbourhood='Saint-Léonard', \n",
    "                        distances_by_transportation=walking_distances, \n",
    "                        amenity='hospital')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_neighborhood_graph(transportation_type='walking',\n",
    "                        neighbourhood='Anjou', \n",
    "                        distances_by_transportation=walking_distances, \n",
    "                        amenity='restaurant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_neighborhood_graph(transportation_type='biking',\n",
    "                        neighbourhood='Anjou', \n",
    "                        distances_by_transportation=biking_distances, \n",
    "                        amenity='hospital')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_neighborhood_graph(transportation_type='walking',\n",
    "                        neighbourhood='Le Plateau-Mont-Royal', \n",
    "                        distances_by_transportation=walking_distances, \n",
    "                        amenity='cafe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
